{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import hickle as hkl\n",
    "from numpy import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "from keras.models import Model\n",
    "# from keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, Dense, Embedding\n",
    "from keras.layers import concatenate, Input, LSTM, GRU, merge, Lambda, Dot, Add, Multiply, \\\n",
    "wrappers, Dropout, GlobalAveragePooling1D, Bidirectional, BatchNormalization, Activation\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Reshape\n",
    "import keras.backend as K\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.layers import LSTM, Dense\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import keras.backend as KTF\n",
    "import tensorflow as tf\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# config = tf.ConfigProto()\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "KTF.set_session(sess)\n",
    "\n",
    "# test_data_path = 'test_pred/'\n",
    "test_data_path = 'C:/Users/13528/Task 1/test_pred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "\n",
    "# data_path = 'Skip_Data/'\n",
    "data_path = 'C:/Users/13528/Task 1/Skip Data/'\n",
    "\n",
    "le_track_id = joblib.load('le_track_id.pkl')\n",
    "\n",
    "spotify_song_fea = pd.read_parquet('spotify_song_fea.parquet')\n",
    "\n",
    "le = LabelEncoder()\n",
    "##\n",
    "spotify_song_fea['mode'] = le.fit_transform(spotify_song_fea['mode'])\n",
    "\n",
    "track_id = np.array(spotify_song_fea['track_id'])\n",
    "\n",
    "cols_to_be_normalized = ['duration', 'release_year', 'us_popularity_estimate',\n",
    "       'acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "       'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'key',\n",
    "       'liveness', 'loudness', 'mechanism', 'mode', 'organism', 'speechiness',\n",
    "       'tempo', 'time_signature', 'valence', 'acoustic_vector_0',\n",
    "       'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "       'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "       'acoustic_vector_7']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "spotify_song_array = scaler.fit_transform(spotify_song_fea[cols_to_be_normalized])\n",
    "\n",
    "order = np.argsort(track_id)\n",
    "spotify_song_array = spotify_song_array[order,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "batch_size = 1500 # skip_net_glove_max_mtsk_more_layer_best\n",
    "\n",
    "batch_size = 3000 # skip_net_glove_max_mtsk_more_layer_best_v2\n",
    "\n",
    "batch_size = 3000 # skip_net_glove_max_mtsk_more_layer_best_bn\n",
    "\n",
    "data_path = 'Skip_Data/'\n",
    "\n",
    "le_track_id = joblib.load('le_track_id.pkl')\n",
    "\n",
    "spotify_song_fea = pd.read_parquet('spotify_song_fea.parquet')\n",
    "\n",
    "le = LabelEncoder()\n",
    "##\n",
    "spotify_song_fea['mode'] = le.fit_transform(spotify_song_fea['mode'])\n",
    "\n",
    "track_id = np.array(spotify_song_fea['track_id'])\n",
    "\n",
    "spotify_song_fea['duration'] = spotify_song_fea['duration']/100\n",
    "spotify_song_fea['release_year'] = spotify_song_fea['release_year']-1950\n",
    "spotify_song_fea['us_popularity_estimate'] = spotify_song_fea['us_popularity_estimate'] - 90\n",
    "\n",
    "spotify_song_fea['duration_05'] = spotify_song_fea['duration']**0.5\n",
    "spotify_song_fea['duration_15'] = spotify_song_fea['duration']**1.5\n",
    "spotify_song_fea['duration_2'] = spotify_song_fea['duration']**2\n",
    "spotify_song_fea['duration_3'] = spotify_song_fea['duration']**3\n",
    "\n",
    "spotify_song_fea['release_year_05'] = spotify_song_fea['release_year']**0.5\n",
    "spotify_song_fea['release_year_15'] = spotify_song_fea['release_year']**1.5\n",
    "spotify_song_fea['release_year_2'] = spotify_song_fea['release_year']**2\n",
    "spotify_song_fea['release_year_3'] = spotify_song_fea['release_year']**3\n",
    "\n",
    "spotify_song_fea['us_popularity_estimate_15'] = spotify_song_fea['us_popularity_estimate']**1.5\n",
    "spotify_song_fea['us_popularity_estimate_2'] = spotify_song_fea['us_popularity_estimate']**2\n",
    "spotify_song_fea['us_popularity_estimate_3'] = spotify_song_fea['us_popularity_estimate']**3\n",
    "\n",
    "cols_to_be_normalized = ['us_popularity_estimate_3', 'us_popularity_estimate_2', 'us_popularity_estimate_15', 'release_year_05','release_year_15','release_year_2','duration_05','duration_15','duration_2','duration', 'release_year', 'us_popularity_estimate',\n",
    "       'acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "       'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'key',\n",
    "       'liveness', 'loudness', 'mechanism', 'mode', 'organism', 'speechiness',\n",
    "       'tempo', 'time_signature', 'valence', 'acoustic_vector_0',\n",
    "       'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "       'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "       'acoustic_vector_7']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "spotify_song_array = scaler.fit_transform(spotify_song_fea[cols_to_be_normalized])\n",
    "\n",
    "order = np.argsort(track_id)\n",
    "spotify_song_array = spotify_song_array[order,:]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_zero_embedding = -2*np.ones((1,spotify_song_array.shape[1]))\n",
    "spotify_song_array = np.concatenate((song_zero_embedding,spotify_song_array),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706389, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_song_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify_song_array_glove = hkl.load('song_embedding_matrix_150.hkl')\n",
    "spotify_song_array_glove = joblib.load('song_embedding_matrix_150.pkl')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "spotify_song_array = np.concatenate((spotify_song_array,spotify_song_array_glove),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706389, 179)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_song_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_context_type = joblib.load(data_path+'le_context_type.pkl')\n",
    "le_reason_start = joblib.load(data_path+'le_reason_start.pkl')\n",
    "le_reason_end = joblib.load(data_path+'le_reason_end.pkl')\n",
    "\n",
    "# n_context_type = len(le_context_type.classes_) + 1\n",
    "# n_reason_start = len(le_reason_start.classes_) + 1\n",
    "# n_reason_end = len(le_reason_end.classes_) + 1\n",
    "n_context_type = len(le_context_type.unique())\n",
    "n_reason_start = len(le_reason_start.unique())\n",
    "n_reason_end = len(le_reason_end.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob.glob(test_data_path + 'pred_*.parquet')\n",
    "len(test_files)\n",
    "test_files = list(np.sort(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = list(np.sort(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/13528/Task 1/test_pred\\\\pred_20180715.parquet']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TestPredProcessSessionCate(pred_df):\n",
    "    session_cols = ['session_id', 'session_position', 'session_length', 'track_id_clean']\n",
    "\n",
    "    pred_df['track_id_clean'] = pred_df['track_id_clean'] + 1\n",
    "    \n",
    "    output_raw_data = np.array(pred_df[session_cols].values) * 1\n",
    "    output_raw_data = output_raw_data.astype(np.float)\n",
    "\n",
    "    output_raw_data_first_p = np.floor(output_raw_data[:, 2] / 2).astype(np.int)\n",
    "    output_raw_data_first_p = -output_raw_data_first_p + output_raw_data[:, 1]\n",
    "\n",
    "    n_session = int(np.max(output_raw_data[:,0])) + 1\n",
    "    gc.collect()\n",
    "    output_data = -2 * np.ones((n_session * 10, 2))\n",
    "    \n",
    "    output_raw_data[:,2] = output_raw_data[:,1]/output_raw_data[:,2]\n",
    "\n",
    "    output_data[output_raw_data[:, 0].astype(np.int) * 10 + output_raw_data_first_p.astype(np.int) - 1,\n",
    "    :] = output_raw_data[:, 2:4]\n",
    "    output_data = np.reshape(output_data, (n_session, 10, output_data.shape[1]))\n",
    "\n",
    "    output_data_id = output_data[:,:,1]\n",
    "    \n",
    "    output_data = output_data[:,:,0]\n",
    "    \n",
    "    output_data_id[output_data_id<0] = 0    \n",
    "    output_data_id = output_data_id.astype(int)\n",
    "\n",
    "    return output_data, output_data_id\n",
    "\n",
    "\n",
    "def TestPreHistSessionCate(pre_hist_df):\n",
    "#     pre_hist_df['context_type'] = le_context_type.transform(pre_hist_df['context_type'])\n",
    "#     pre_hist_df['hist_user_behavior_reason_start'] = le_reason_start.transform(pre_hist_df['hist_user_behavior_reason_start'])\n",
    "#     pre_hist_df['hist_user_behavior_reason_end'] = le_reason_end.transform(pre_hist_df['hist_user_behavior_reason_end'])\n",
    "    pre_hist_df['context_type'] = le.fit_transform(pre_hist_df['context_type'])\n",
    "    pre_hist_df['hist_user_behavior_reason_start'] = le.fit_transform(pre_hist_df['hist_user_behavior_reason_start'])\n",
    "    pre_hist_df['hist_user_behavior_reason_end'] = le.fit_transform(pre_hist_df['hist_user_behavior_reason_end'])\n",
    "    session_cols = ['session_id', 'session_position', 'session_length', 'track_id_clean',\n",
    "                    'skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch',\n",
    "                    'no_pause_before_play', 'short_pause_before_play',\n",
    "                    'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "                    'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "                    'hour_of_day', 'premium', 'context_type',\n",
    "                    'hist_user_behavior_reason_start', 'hist_user_behavior_reason_end']\n",
    "\n",
    "    pre_hist_df['track_id_clean'] = pre_hist_df['track_id_clean'] + 1\n",
    "    pre_hist_df['hour_of_day'] = pre_hist_df['hour_of_day']/24\n",
    "\n",
    "    input_raw_data = np.array(pre_hist_df[session_cols].values) * 1\n",
    "    input_raw_data = input_raw_data.astype(np.float)\n",
    "\n",
    "    input_raw_data_final_p = np.floor(input_raw_data[:, 2]/2).astype(np.int)\n",
    "    input_raw_data_final_p = 10 - input_raw_data_final_p + input_raw_data[:, 1]\n",
    "\n",
    "    n_session = int(np.max(input_raw_data[:,0])) + 1\n",
    "    gc.collect()\n",
    "    input_data = -2 * np.ones((n_session * 10, 18))\n",
    "\n",
    "    input_data[:, 17] = n_reason_end - 1    \n",
    "    input_data[:, 16] = n_reason_start - 1    \n",
    "    input_data[:, 15] = n_context_type - 1\n",
    "    \n",
    "    input_raw_data[:,2] = input_raw_data[:,1]/input_raw_data[:,2]\n",
    "\n",
    "    input_data[input_raw_data[:, 0].astype(np.int) * 10 + input_raw_data_final_p.astype(np.int) - 1,\n",
    "    :] = input_raw_data[:, 2:20]\n",
    "    input_data = np.reshape(input_data, (n_session, 10, input_data.shape[1]))\n",
    "\n",
    "    input_data_context_id = input_data[:,:,15]\n",
    "    input_data_start_id = input_data[:,:,16]\n",
    "    input_data_end_id = input_data[:,:,17]\n",
    "\n",
    "    input_data = input_data[:,:,range(15)]\n",
    "\n",
    "    input_data_id = input_data[:,:,1]\n",
    "    input_data = np.delete(input_data, 1, 2)\n",
    "    \n",
    "    input_data_context_id[input_data_context_id<0] = 0\n",
    "    input_data_start_id[input_data_start_id<0] = 0\n",
    "    input_data_end_id[input_data_end_id<0] = 0\n",
    "    input_data_id[input_data_id<0] = 0\n",
    "    \n",
    "    input_data_context_id = input_data_context_id.astype(int)\n",
    "    input_data_start_id = input_data_start_id.astype(int)\n",
    "    input_data_end_id = input_data_end_id.astype(int)\n",
    "    input_data_id = input_data_id.astype(int)\n",
    "    \n",
    "\n",
    "    return input_data, input_data_context_id, input_data_start_id, input_data_end_id,input_data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_id (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " context (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " start (InputLayer)             [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " end (InputLayer)               [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_fea (InputLayer)         [(None, 10, 14)]     0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 10, 179)      663443631   ['input_id[0][0]',               \n",
      "                                                                  'output_id[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 10, 25)       150         ['context[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 10, 25)       275         ['start[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 10, 25)       250         ['end[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10, 268)      0           ['input_fea[0][0]',              \n",
      "                                                                  'embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]',            \n",
      "                                                                  'embedding_2[0][0]',            \n",
      "                                                                  'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " gru (GRU)                      [(None, 10, 350),    651000      ['concatenate[0][0]']            \n",
      "                                 (None, 350)]                                                     \n",
      "                                                                                                  \n",
      " output_fea (InputLayer)        [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " output_id (InputLayer)         [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    [(None, 10, 350),    737100      ['gru[0][0]']                    \n",
      "                                 (None, 350)]                                                     \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 10, 1)        0           ['output_fea[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 700)          0           ['gru[0][1]',                    \n",
      "                                                                  'gru_1[0][1]']                  \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 10, 180)      0           ['reshape[0][0]',                \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 700)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10, 700)      126700      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 10, 700)      0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 10, 700)      0           ['dense[0][0]',                  \n",
      "                                                                  'concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 10, 2100)     0           ['lambda[0][0]',                 \n",
      "                                                                  'multiply[0][0]',               \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 10, 700)      5149200     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 10, 700)     2209200     ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 10, 400)     1082400     ['bidirectional_1[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 10, 400)     722400      ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 10, 4300)     0           ['concatenate_3[0][0]',          \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'bidirectional_2[0][0]',        \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10, 1000)     4301000     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10, 784)      784784      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 10, 784)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10, 11)       8635        ['dropout[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 679,216,725\n",
      "Trainable params: 15,773,094\n",
      "Non-trainable params: 663,443,631\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13528\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tile_tile(X):\n",
    "    X = K.tile(X, [1,10,1]) \n",
    "    return X\n",
    "\n",
    "\n",
    "def exp_smooth5(X):   \n",
    "    weight = np.power(0.5,9 - np.arange(10))\n",
    "    weight = weight/np.sum(weight)\n",
    "    weight = np.reshape(weight, (1,10,1))\n",
    "    att_output_weight = K.variable(weight)\n",
    "    print(att_output_weight.shape)\n",
    "    att_output_result = X*att_output_weight    \n",
    "    print(X.shape)\n",
    "    att_output_result = K.mean(att_output_result, axis=1)\n",
    "    \n",
    "    return att_output_result\n",
    "\n",
    "def exp_smooth8(X):   \n",
    "    weight = np.power(0.8,9 - np.arange(10))\n",
    "    weight = weight/np.sum(weight)\n",
    "    weight = np.reshape(weight, (1,10,1))\n",
    "    att_output_weight = K.variable(weight)\n",
    "    print(att_output_weight.shape)\n",
    "    att_output_result = X*att_output_weight    \n",
    "    print(X.shape)\n",
    "    att_output_result = K.mean(att_output_result, axis=1)\n",
    "    \n",
    "    return att_output_result\n",
    "\n",
    "\n",
    "class mstk_ndcg_callback(Callback):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):      \n",
    "\n",
    "        y_pred = self.model.predict(X_valid,batch_size=800)\n",
    "        \n",
    "        hkl.dump(y_pred, data_path+'y_pred.hkl', mode='w', compression='gzip')\n",
    "        \n",
    "        y_pred = y_pred[:,:,1]\n",
    "        \n",
    "        Y_valid_i = Y_valid[:,:,1]\n",
    "        \n",
    "        Y_pred = 0*y_pred\n",
    "        Y_pred[y_pred>=0.5] = 1\n",
    "        \n",
    "        Y_pred = (Y_pred==Y_valid_i)\n",
    "        \n",
    "        Y_pred = Y_pred[valid_output>=0]\n",
    "        \n",
    "        #print(Y_pred.shape)\n",
    "\n",
    "        print(np.mean(Y_pred))\n",
    "        \n",
    "        #hkl.dump(song_embedding_matrix, data_path+'song_embedding_matrix_80.hkl', mode='w', compression='gzip')\n",
    "\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "#K.clear_session()\n",
    "\n",
    "#spotify_song_array = np.ones((100,2))\n",
    "#input_fea_dim = 5\n",
    "#n_context_type = 4\n",
    "#n_reason_start = 3\n",
    "#n_reason_end = 3\n",
    "\n",
    "def skip_model_5_mtsk_att(cell_size = 350):\n",
    "\n",
    "    input_data_context_id = Input(shape=[10], name=\"context\")\n",
    "    input_data_start_id = Input(shape=[10], name=\"start\")\n",
    "    input_data_end_id = Input(shape=[10], name=\"end\")\n",
    "    input_data = Input(shape=[10,14], name=\"input_fea\")\n",
    "    output_data_i = Input(shape=[10], name=\"output_fea\")\n",
    "    input_id = Input(shape=[10], name=\"input_id\")\n",
    "    output_id = Input(shape=[10], name=\"output_id\")\n",
    "\n",
    "    song_emb_layer = Embedding(\n",
    "        input_dim=spotify_song_array.shape[0],\n",
    "        output_dim=spotify_song_array.shape[1],\n",
    "        weights=[spotify_song_array],\n",
    "        trainable=False\n",
    "    )\n",
    "\n",
    "    context_emb_layer = Embedding(n_context_type,25)\n",
    "    reason_start_emb_layer = Embedding(n_reason_start,25)\n",
    "    reason_end_emb_layer = Embedding(n_reason_end,25)\n",
    "\n",
    "    emb_input_id = song_emb_layer(input_id)\n",
    "    emb_output_id = song_emb_layer(output_id)\n",
    "    emb_input_data_context_id = context_emb_layer(input_data_context_id)\n",
    "    emb_input_data_start_id = reason_start_emb_layer(input_data_start_id)\n",
    "    emb_input_data_end_id = reason_end_emb_layer(input_data_end_id)\n",
    "\n",
    "    input_data_a = concatenate([input_data,emb_input_id,emb_input_data_context_id,\n",
    "                              emb_input_data_start_id,emb_input_data_end_id])\n",
    "\n",
    "    # rnn layers\n",
    "#    encoder_outputs, state_h\n",
    "    \n",
    "    encoder_outputs, rnn_layer = GRU(cell_size, return_sequences=True, return_state=True) (input_data_a)\n",
    "    \n",
    "    encoder_outputs_1, rnn_layer_1 = GRU(cell_size, return_sequences=True, return_state=True) (encoder_outputs)\n",
    "    \n",
    "    #rnn_layer_5 = Lambda(exp_smooth5)(encoder_outputs)    \n",
    "    #rnn_layer_8 = Lambda(exp_smooth8)(encoder_outputs)    \n",
    "#    print(encoder_outputs.shape)\n",
    "#    print(rnn_layer_5.shape)\n",
    "#    print(rnn_layer.shape)\n",
    "\n",
    "    \n",
    "    rnn_layer = concatenate([rnn_layer, rnn_layer_1])\n",
    "    \n",
    "    output_data = Reshape([10,1])(output_data_i)\n",
    "    \n",
    "    output_data = concatenate([output_data, emb_output_id])\n",
    "\n",
    "    output_data = Dense(2*cell_size, activation='relu')(output_data)\n",
    "\n",
    "    rnn_layer_multi = Multiply()([output_data, rnn_layer])\n",
    "    \n",
    "    rnn_layer_reshape = Reshape([1,2*cell_size])(rnn_layer)\n",
    "    \n",
    "    rnn_layer_reshape = Lambda(tile_tile)(rnn_layer_reshape)\n",
    "\n",
    "    output_result = concatenate([rnn_layer_reshape, rnn_layer_multi, output_data])\n",
    "    \n",
    "    output_rnn_layer = Bidirectional(GRU(cell_size, return_sequences=True))(output_result)\n",
    "    \n",
    "    output_rnn_layer_2 = Bidirectional(GRU(cell_size, return_sequences=True))(output_rnn_layer)\n",
    "    \n",
    "    output_rnn_layer_3 = Bidirectional(GRU(200, return_sequences=True))(output_rnn_layer_2)\n",
    "    \n",
    "    output_rnn_layer_4 = Bidirectional(GRU(200, return_sequences=True))(output_rnn_layer_3)\n",
    "    \n",
    "    output_result = concatenate([output_result, output_rnn_layer, output_rnn_layer_2, output_rnn_layer_3, output_rnn_layer_4])\n",
    "\n",
    "    output_result = Dense(1000, activation='relu')(output_result)\n",
    "    output_result_1 = Dense(784, activation='relu')(output_result)\n",
    "    #output_result_2 = Dense(784, activation='elu')(output_result_1)\n",
    "    \n",
    "    #output_result = concatenate([output_result, output_result_1, output_result_2])\n",
    "    \n",
    "    output_result = Dropout(0.2)(output_result_1)\n",
    "\n",
    "    output_result = Dense(11, activation='sigmoid')(output_result)\n",
    "    \n",
    "    #output_result = Reshape([10])(output_result)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[input_data_context_id, input_data_start_id,\n",
    "                          input_data_end_id, input_data, output_data_i, input_id, output_id], outputs=output_result)\n",
    "\n",
    "    sgd = Adam(lr=0.0008)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy', 'binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = skip_model_5_mtsk_att()\n",
    "\n",
    "# model.load_weights('Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5')\n",
    "model.load_weights('C:/Users/13528/Task 1/Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/13528/Task 1/test_pred\\pred_20180715.parquet\n",
      "         session_id  track_id_clean  session_position  session_length\n",
      "0                 0          671463                 9              16\n",
      "1                 0         3638841                10              16\n",
      "2                 0           43169                11              16\n",
      "3                 0         2756540                12              16\n",
      "4                 0         2455651                13              16\n",
      "...             ...             ...               ...             ...\n",
      "3777542      444490         2317225                11              15\n",
      "3777543      444490         1164819                12              15\n",
      "3777544      444490          612229                13              15\n",
      "3777545      444490         1164819                14              15\n",
      "3777546      444490          612229                15              15\n",
      "\n",
      "[3777547 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         session_id  session_position  session_length  track_id_clean  skip_1  \\\n",
      "0                 0                 1              16         2326848   False   \n",
      "1                 0                 2              16         2455651   False   \n",
      "2                 0                 3              16         2193820   False   \n",
      "3                 0                 4              16         3284397   False   \n",
      "4                 0                 5              16         2563607    True   \n",
      "...             ...               ...             ...             ...     ...   \n",
      "3673815      444490                 3              15         2410051    True   \n",
      "3673816      444490                 4              15         2410051    True   \n",
      "3673817      444490                 5              15         2317225    True   \n",
      "3673818      444490                 6              15         1164819    True   \n",
      "3673819      444490                 7              15         2317225    True   \n",
      "\n",
      "         skip_2  skip_3  not_skipped  context_switch  no_pause_before_play  \\\n",
      "0          True    True        False               0                     0   \n",
      "1         False    True        False               1                     1   \n",
      "2         False   False         True               0                     0   \n",
      "3          True    True        False               0                     0   \n",
      "4          True    True        False               0                     1   \n",
      "...         ...     ...          ...             ...                   ...   \n",
      "3673815    True    True        False               0                     0   \n",
      "3673816    True    True        False               0                     1   \n",
      "3673817    True    True        False               0                     1   \n",
      "3673818    True    True        False               0                     1   \n",
      "3673819    True    True        False               0                     1   \n",
      "\n",
      "         ...  long_pause_before_play  hist_user_behavior_n_seekfwd  \\\n",
      "0        ...                       0                             1   \n",
      "1        ...                       0                             0   \n",
      "2        ...                       1                             0   \n",
      "3        ...                       1                             0   \n",
      "4        ...                       0                             0   \n",
      "...      ...                     ...                           ...   \n",
      "3673815  ...                       1                             0   \n",
      "3673816  ...                       0                             0   \n",
      "3673817  ...                       0                             0   \n",
      "3673818  ...                       0                             0   \n",
      "3673819  ...                       0                             0   \n",
      "\n",
      "         hist_user_behavior_n_seekback  hist_user_behavior_is_shuffle  \\\n",
      "0                                    0                          False   \n",
      "1                                    0                          False   \n",
      "2                                    1                          False   \n",
      "3                                    0                          False   \n",
      "4                                    0                          False   \n",
      "...                                ...                            ...   \n",
      "3673815                              0                           True   \n",
      "3673816                              0                           True   \n",
      "3673817                              0                           True   \n",
      "3673818                              0                           True   \n",
      "3673819                              0                           True   \n",
      "\n",
      "         hour_of_day        date premium     context_type  \\\n",
      "0                 21  2018-07-14   False          catalog   \n",
      "1                 21  2018-07-14   False  user_collection   \n",
      "2                 21  2018-07-14   False  user_collection   \n",
      "3                 21  2018-07-14   False  user_collection   \n",
      "4                 21  2018-07-14   False  user_collection   \n",
      "...              ...         ...     ...              ...   \n",
      "3673815           11  2018-07-15   False          catalog   \n",
      "3673816           11  2018-07-15   False          catalog   \n",
      "3673817           11  2018-07-15   False          catalog   \n",
      "3673818           11  2018-07-15   False          catalog   \n",
      "3673819           11  2018-07-15   False          catalog   \n",
      "\n",
      "        hist_user_behavior_reason_start hist_user_behavior_reason_end  \n",
      "0                               appload                       endplay  \n",
      "1                              clickrow                       endplay  \n",
      "2                              clickrow                     trackdone  \n",
      "3                             trackdone                        fwdbtn  \n",
      "4                                fwdbtn                        fwdbtn  \n",
      "...                                 ...                           ...  \n",
      "3673815                       trackdone                        fwdbtn  \n",
      "3673816                          fwdbtn                        fwdbtn  \n",
      "3673817                          fwdbtn                        fwdbtn  \n",
      "3673818                          fwdbtn                       backbtn  \n",
      "3673819                         backbtn                        fwdbtn  \n",
      "\n",
      "[3673820 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(test_files):\n",
    "    print(item)\n",
    "    preddf = pd.read_parquet(item)\n",
    "    print(preddf)\n",
    "    prehistdf = pd.read_parquet(test_data_path + 'prehist_' + item[37:]) \n",
    "    print(prehistdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180715\n",
      "C:/Users/13528/Task 1/test_pred\\pred_20180715.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(test_files):\n",
    "    print(item[37:45])\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]C:\\Users\\13528\\AppData\\Local\\Temp/ipykernel_26768/4041258585.py:51: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  input_raw_data = input_raw_data.astype(np.float)\n",
      "C:\\Users\\13528\\AppData\\Local\\Temp/ipykernel_26768/4041258585.py:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  input_raw_data_final_p = np.floor(input_raw_data[:, 2]/2).astype(np.int)\n",
      "C:\\Users\\13528\\AppData\\Local\\Temp/ipykernel_26768/4041258585.py:66: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  input_data[input_raw_data[:, 0].astype(np.int) * 10 + input_raw_data_final_p.astype(np.int) - 1,\n",
      "C:\\Users\\13528\\AppData\\Local\\Temp/ipykernel_26768/4041258585.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  output_raw_data = output_raw_data.astype(np.float)\n",
      "C:\\Users\\13528\\AppData\\Local\\Temp/ipykernel_26768/4041258585.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  output_raw_data_first_p = np.floor(output_raw_data[:, 2] / 2).astype(np.int)\n",
      "C:\\Users\\13528\\AppData\\Local\\Temp/ipykernel_26768/4041258585.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  output_data[output_raw_data[:, 0].astype(np.int) * 10 + output_raw_data_first_p.astype(np.int) - 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 690s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [11:44<00:00, 704.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45986274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(test_files):\n",
    "    preddf = pd.read_parquet(item)\n",
    "    \n",
    "#     prehistdf = pd.read_parquet(test_data_path + 'prehist_' + item[15:])\n",
    "    prehistdf = pd.read_parquet(test_data_path + 'prehist_' + item[37:])\n",
    "    \n",
    "    cols = ['session_id', 'session_position', 'session_length', 'track_id_clean']\n",
    "    \n",
    "    preddf = preddf[cols]    \n",
    "    \n",
    "    input_data, input_data_context_id, input_data_start_id, input_data_end_id,input_data_id = TestPreHistSessionCate(prehistdf)\n",
    "    \n",
    "    output_data, output_data_id = TestPredProcessSessionCate(preddf)\n",
    "    \n",
    "    X_test = {\n",
    "       'context': input_data_context_id,\n",
    "        'start': input_data_start_id,\n",
    "        'end': input_data_end_id,\n",
    "        'input_fea': input_data,\n",
    "         'output_fea': output_data,\n",
    "        'input_id': input_data_id,\n",
    "        'output_id': output_data_id,\n",
    "        }\n",
    "    \n",
    "    y_pred = model.predict(X_test,batch_size=1500,verbose=1)\n",
    "    y_pred = y_pred[:,:,1]\n",
    "    \n",
    "    print(np.mean(y_pred))\n",
    "        \n",
    "#     hkl.dump(y_pred, data_path+item[37:45]+'_y_pred_mtsk_larger_v6.hkl', mode='w', compression='gzip')\n",
    "    joblib.dump(y_pred, data_path+item[37:45]+'_y_pred_mtsk_larger_v6.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_id (InputLayer)           (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "start (InputLayer)              (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "end (InputLayer)                (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_fea (InputLayer)          (None, 10, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 179)      663443631   input_id[0][0]                   \n",
      "                                                                 output_id[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 10, 25)       175         context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 10, 25)       325         start[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 10, 25)       300         end[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 268)      0           input_fea[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 10, 350), (N 649950      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_fea (InputLayer)         (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output_id (InputLayer)          (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, 10, 350), (N 736050      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 1)        0           output_fea[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 700)          0           gru_1[0][1]                      \n",
      "                                                                 gru_2[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10, 180)      0           reshape_1[0][0]                  \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 700)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10, 700)      126700      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10, 700)      0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 10, 700)      0           dense_1[0][0]                    \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 10, 2100)     0           lambda_1[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 10, 700)      5147100     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 700)      2207100     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 10, 400)      1081200     bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 10, 400)      721200      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 10, 4300)     0           concatenate_4[0][0]              \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10, 1000)     4301000     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10, 784)      784784      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10, 784)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10, 11)       8635        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 679,208,150\n",
      "Trainable params: 15,764,519\n",
      "Non-trainable params: 663,443,631\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "def tile_tile(X):\n",
    "    X = K.tile(X, [1,10,1]) \n",
    "    return X\n",
    "\n",
    "\n",
    "def exp_smooth5(X):   \n",
    "    weight = np.power(0.5,9 - np.arange(10))\n",
    "    weight = weight/np.sum(weight)\n",
    "    weight = np.reshape(weight, (1,10,1))\n",
    "    att_output_weight = K.variable(weight)\n",
    "    print(att_output_weight.shape)\n",
    "    att_output_result = X*att_output_weight    \n",
    "    print(X.shape)\n",
    "    att_output_result = K.mean(att_output_result, axis=1)\n",
    "    \n",
    "    return att_output_result\n",
    "\n",
    "def exp_smooth8(X):   \n",
    "    weight = np.power(0.8,9 - np.arange(10))\n",
    "    weight = weight/np.sum(weight)\n",
    "    weight = np.reshape(weight, (1,10,1))\n",
    "    att_output_weight = K.variable(weight)\n",
    "    print(att_output_weight.shape)\n",
    "    att_output_result = X*att_output_weight    \n",
    "    print(X.shape)\n",
    "    att_output_result = K.mean(att_output_result, axis=1)\n",
    "    \n",
    "    return att_output_result\n",
    "\n",
    "\n",
    "class mstk_ndcg_callback(Callback):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):      \n",
    "\n",
    "        y_pred = self.model.predict(X_valid,batch_size=800)\n",
    "        \n",
    "        hkl.dump(y_pred, data_path+'y_pred.hkl', mode='w', compression='gzip')\n",
    "        \n",
    "        y_pred = y_pred[:,:,1]\n",
    "        \n",
    "        Y_valid_i = Y_valid[:,:,1]\n",
    "        \n",
    "        Y_pred = 0*y_pred\n",
    "        Y_pred[y_pred>=0.5] = 1\n",
    "        \n",
    "        Y_pred = (Y_pred==Y_valid_i)\n",
    "        \n",
    "        Y_pred = Y_pred[valid_output>=0]\n",
    "        \n",
    "        #print(Y_pred.shape)\n",
    "\n",
    "        print(np.mean(Y_pred))\n",
    "        \n",
    "        #hkl.dump(song_embedding_matrix, data_path+'song_embedding_matrix_80.hkl', mode='w', compression='gzip')\n",
    "\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "#K.clear_session()\n",
    "\n",
    "#spotify_song_array = np.ones((100,2))\n",
    "#input_fea_dim = 5\n",
    "#n_context_type = 4\n",
    "#n_reason_start = 3\n",
    "#n_reason_end = 3\n",
    "\n",
    "def skip_model_5_mtsk_att(cell_size = 350):\n",
    "\n",
    "    input_data_context_id = Input(shape=[10], name=\"context\")\n",
    "    input_data_start_id = Input(shape=[10], name=\"start\")\n",
    "    input_data_end_id = Input(shape=[10], name=\"end\")\n",
    "    input_data = Input(shape=[10,14], name=\"input_fea\")\n",
    "    output_data_i = Input(shape=[10], name=\"output_fea\")\n",
    "    input_id = Input(shape=[10], name=\"input_id\")\n",
    "    output_id = Input(shape=[10], name=\"output_id\")\n",
    "\n",
    "    song_emb_layer = Embedding(\n",
    "        input_dim=spotify_song_array.shape[0],\n",
    "        output_dim=spotify_song_array.shape[1],\n",
    "        weights=[spotify_song_array],\n",
    "        trainable=False\n",
    "    )\n",
    "\n",
    "    context_emb_layer = Embedding(n_context_type,25)\n",
    "    reason_start_emb_layer = Embedding(n_reason_start,25)\n",
    "    reason_end_emb_layer = Embedding(n_reason_end,25)\n",
    "\n",
    "    emb_input_id = song_emb_layer(input_id)\n",
    "    emb_output_id = song_emb_layer(output_id)\n",
    "    emb_input_data_context_id = context_emb_layer(input_data_context_id)\n",
    "    emb_input_data_start_id = reason_start_emb_layer(input_data_start_id)\n",
    "    emb_input_data_end_id = reason_end_emb_layer(input_data_end_id)\n",
    "\n",
    "    input_data_a = concatenate([input_data,emb_input_id,emb_input_data_context_id,\n",
    "                              emb_input_data_start_id,emb_input_data_end_id])\n",
    "\n",
    "    # rnn layers\n",
    "#    encoder_outputs, state_h\n",
    "    \n",
    "    encoder_outputs, rnn_layer = GRU(cell_size, return_sequences=True, return_state=True) (input_data_a)\n",
    "    \n",
    "    encoder_outputs_1, rnn_layer_1 = GRU(cell_size, return_sequences=True, return_state=True) (encoder_outputs)\n",
    "    \n",
    "    #rnn_layer_5 = Lambda(exp_smooth5)(encoder_outputs)    \n",
    "    #rnn_layer_8 = Lambda(exp_smooth8)(encoder_outputs)    \n",
    "#    print(encoder_outputs.shape)\n",
    "#    print(rnn_layer_5.shape)\n",
    "#    print(rnn_layer.shape)\n",
    "\n",
    "    \n",
    "    rnn_layer = concatenate([rnn_layer, rnn_layer_1])\n",
    "    \n",
    "    output_data = Reshape([10,1])(output_data_i)\n",
    "    \n",
    "    output_data = concatenate([output_data, emb_output_id])\n",
    "\n",
    "    output_data = Dense(2*cell_size, activation='relu')(output_data)\n",
    "\n",
    "    rnn_layer_multi = Multiply()([output_data, rnn_layer])\n",
    "    \n",
    "    rnn_layer_reshape = Reshape([1,2*cell_size])(rnn_layer)\n",
    "    \n",
    "    rnn_layer_reshape = Lambda(tile_tile)(rnn_layer_reshape)\n",
    "\n",
    "    output_result = concatenate([rnn_layer_reshape, rnn_layer_multi, output_data])\n",
    "    \n",
    "    output_rnn_layer = Bidirectional(GRU(cell_size, return_sequences=True))(output_result)\n",
    "    \n",
    "    output_rnn_layer_2 = Bidirectional(GRU(cell_size, return_sequences=True))(output_rnn_layer)\n",
    "    \n",
    "    output_rnn_layer_3 = Bidirectional(GRU(200, return_sequences=True))(output_rnn_layer_2)\n",
    "    \n",
    "    output_rnn_layer_4 = Bidirectional(GRU(200, return_sequences=True))(output_rnn_layer_3)\n",
    "    \n",
    "    output_result = concatenate([output_result, output_rnn_layer, output_rnn_layer_2, output_rnn_layer_3, output_rnn_layer_4])\n",
    "\n",
    "    output_result = Dense(1000, activation='relu')(output_result)\n",
    "    output_result_1 = Dense(784, activation='relu')(output_result)\n",
    "    #output_result_2 = Dense(784, activation='elu')(output_result_1)\n",
    "    \n",
    "    #output_result = concatenate([output_result, output_result_1, output_result_2])\n",
    "    \n",
    "    output_result = Dropout(0.2)(output_result_1)\n",
    "\n",
    "    output_result = Dense(11, activation='sigmoid')(output_result)\n",
    "    \n",
    "    #output_result = Reshape([10])(output_result)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[input_data_context_id, input_data_start_id,\n",
    "                          input_data_end_id, input_data, output_data_i, input_id, output_id], outputs=output_result)\n",
    "\n",
    "    sgd = Adam(lr=0.0008)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy', 'binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = skip_model_5_mtsk_att()\n",
    "\n",
    "model.load_weights('Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_reason_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
